from sklearn.decomposition import PCA
import numpy as np
import pandas as pd

# '''
#     通过构造数据测试PCA数据降维，并实现PCA函数
# '''
#
# '''
#     Test 1：库函数
# '''
# X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
# print(X)
# '''
#     [[-1 -1]
#      [-2 -1]
#      [-3 -2]
#      [ 1  1]
#      [ 2  1]
#      [ 3  2]]
# '''
#
# # n_components：保留的特征数，默认为1如果设置成mle，会自动确定保留的特征数
# pca = PCA(n_components=1)
# new_X = pca.fit_transform(X)
# print(new_X)
# '''
#     [[ 1.38340578]
#      [ 2.22189802]
#      [ 3.6053038 ]
#      [-1.38340578]
#      [-2.22189802]
#      [-3.6053038 ]]
# '''
#
# # 如果设置成mle，会自动确定保留的特征数
# pca = PCA(n_components='mle')
# new_X = pca.fit_transform(X)
# print(new_X)
# '''
#     [[ 1.38340578]
#      [ 2.22189802]
#      [ 3.6053038 ]
#      [-1.38340578]
#      [-2.22189802]
#      [-3.6053038 ]]
# '''
#
# '''
#     Test 2：库函数
# '''
# # 12条数据分别分布在（1,1）,（2,2）,（3,3）,（4,4）四个点周围，可以看做4类
# data = np.array([[1., 1.],
#                  [0.9, 0.95],
#                  [1.01, 1.03],
#                  [2., 2.],
#                  [2.03, 2.06],
#                  [1.98, 1.89],
#                  [3., 3.],
#                  [3.03, 3.05],
#                  [2.89, 3.1],
#                  [4., 4.],
#                  [4.06, 4.02],
#                  [3.97, 4.01]])
#
# pca = PCA(n_components='mle')
# new_data = pca.fit_transform(data)
# print(new_data)
# '''
#     [[ 2.12015916]
#      [ 2.22617682]
#      [ 2.09185561]
#      [ 0.70594692]
#      [ 0.64227841]
#      [ 0.79795758]
#      [-0.70826533]
#      [-0.76485312]
#      [-0.70139695]
#      [-2.12247757]
#      [-2.17900746]
#      [-2.10837406]]
# '''
#
# '''
#     Test 3：代码实现
# '''
# X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
# print(X)
# '''
#     [[-1 -1]
#      [-2 -1]
#      [-3 -2]
#      [ 1  1]
#      [ 2  1]
#      [ 3  2]]
# '''
#
#
# def myPCA(dataMat, n):
#     # 求数据矩阵每一列的均值
#     meanVals = np.mean(dataMat, axis=0)
#     # print(meanVals)
#     # 数据矩阵每一列特征减去该列的特征均值
#     meanRemoved = dataMat - meanVals
#     # 计算协方差矩阵，除数n-1是为了得到协方差的无偏估计
#     covMat = np.cov(meanRemoved.transpose())
#     # print(covMat)
#     # 计算协方差矩阵的特征值及对应的特征向量
#     eigVals, eigVects = np.linalg.eig(np.mat(covMat))
#     # sort():对特征值矩阵排序(由小到大)
#     # argsort():对特征值矩阵进行由小到大排序，返回对应排序后的索引
#     eigValInd = np.argsort(eigVals)
#     # 从排序后的矩阵最后一个开始自下而上选取最大的N个特征值，返回其对应的索引
#     eigValInd = eigValInd[::-1]
#     eigValInd = eigValInd[:n]
#     # 将特征值最大的N个特征值对应索引的特征向量提取出来，组成压缩矩阵
#     redEigVects = eigVects[:, eigValInd]
#     # 将去除均值后的数据矩阵*压缩矩阵，转换到新的空间，使维度降低为N
#     lowDDataMat = meanRemoved * redEigVects
#     # 返回压缩后的数据矩阵即该矩阵反构出原始数据矩阵
#     return lowDDataMat
#
#
# print(myPCA(X, 1))
# '''
#     [[-1.38340578]
#      [-2.22189802]
#      [-3.6053038 ]
#      [ 1.38340578]
#      [ 2.22189802]
#      [ 3.6053038 ]]
# '''
#
# data = np.array([[1., 1.],
#                  [0.9, 0.95],
#                  [1.01, 1.03],
#                  [2., 2.],
#                  [2.03, 2.06],
#                  [1.98, 1.89],
#                  [3., 3.],
#                  [3.03, 3.05],
#                  [2.89, 3.1],
#                  [4., 4.],
#                  [4.06, 4.02],
#                  [3.97, 4.01]])
#
# print(myPCA(data, 1))
# '''
#     [[ 2.12015916]
#      [ 2.22617682]
#      [ 2.09185561]
#      [ 0.70594692]
#      [ 0.64227841]
#      [ 0.79795758]
#      [-0.70826533]
#      [-0.76485312]
#      [-0.70139695]
#      [-2.12247757]
#      [-2.17900746]
#      [-2.10837406]]
# '''

'''
    PCA降维PaviaU有标记的43776条数据
'''

data = pd.read_csv('../dataset/PaviaU_gt_band_label.csv', header=None)
data = data.as_matrix()
data_content = data[:, :-1]

# 99%降维
pca = PCA(n_components=0.99)
new_content = pca.fit_transform(data_content)
print(data_content.shape)  # (42776, 103)
print(new_content.shape)  # (42776, 4)
print(new_content)
'''
    [[ 8.31852022 -1.8934983   2.64085097  0.29902549]
     [ 7.26488544 -6.54180444 -1.27408002  0.39865372]
     [ 0.47897449 -8.3147756  -3.09284352  0.9651499 ]
     ...
     [ 1.95335336  3.35528482  3.17689018 -0.78792297]
     [ 0.94150065  4.3393509   1.44369467 -0.11790174]
     [-2.83143931  3.19311994  0.53428028 -0.75442757]]
'''

# 99.99%降维
pca = PCA(n_components=0.9999)
new_content = pca.fit_transform(data_content)
print(data_content.shape)  # (42776, 103)
print(new_content.shape)  # (42776, 49)
print(new_content)
'''
    [[ 8.31852022e+00 -1.89349830e+00  2.64085097e+00 ... -6.17610416e-03
       7.58972120e-03  3.06047125e-03]
     [ 7.26488544e+00 -6.54180444e+00 -1.27408002e+00 ... -3.62344668e-03
       1.21815872e-02  2.42180225e-02]
     [ 4.78974491e-01 -8.31477560e+00 -3.09284352e+00 ...  3.16654628e-02
       2.06754491e-02 -5.48509563e-02]
     ...
'''

# 自主降维
pca = PCA(n_components=80)
new_content = pca.fit_transform(data_content)
print(data_content.shape)  # (42776, 103)
print(new_content.shape)  # (42776, 80)
print(new_content)
'''
    [[ 8.31852022e+00 -1.89349830e+00  2.64085097e+00 ... -9.43168553e-03
      -5.59828559e-03  1.61712249e-02]
     [ 7.26488544e+00 -6.54180444e+00 -1.27408002e+00 ...  1.06225632e-02
       1.38908213e-03 -1.11595075e-02]
     [ 4.78974491e-01 -8.31477560e+00 -3.09284352e+00 ...  3.26603278e-04
      -4.59780414e-03 -1.34090746e-04]
     ...
'''
